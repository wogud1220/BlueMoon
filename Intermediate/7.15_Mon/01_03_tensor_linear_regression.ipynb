{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_03_tensor_linear_regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNb+ex4zmA4b/rrXACeB20N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cFc1M-z9Hbxe"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["## data 선언\n","x_data =[[1.],[2.],[3.],[4.]]\n","y_data =[[1.],[3.],[5.],[7.]]"],"metadata":{"id":"NpG_JH7KHd10"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 평균 0, 분산 1의 파라미터의 정규분포로 부터 값을 가져옴.\n","# 학습을 통해 업데이트가 되어 변화되는 모델의 파라미터인 w,b를 의미한다.\n","W=tf.Variable(tf.random.normal((1,1),mean=0, stddev=1.0))\n","b=tf.Variable(tf.random.normal((1,1),mean=0, stddev=1.0))\n","lr=tf.constant(0.0001)"],"metadata":{"id":"IgO81oO9He1R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(2000):  ## 에폭\n","    total_error = 0\n","\n","    for j in range(len(x_data)): ## 배치 1\n","        ## data * weight\n","        WX =tf.matmul([x_data[j]], W)\n","\n","        ## bias add\n","        y_hat = tf.add(WX, b)\n","\n","        ## 정답인 Y와 출력값의 error 계산\n","        error =\n","\n","        ## 경사하강법으로 W와 b 업데이트.\n","        ## 도함수 구하기\n","        diff_W =\n","        diff_b =\n","\n","        ##  업데이트할 만큼 러닝레이트 곱\n","        diff_W =\n","        diff_b =\n","\n","        ## w, b 업데이트\n","        W =\n","        b =\n","        #######\n","\n","        ## 토탈 에러.\n","        total_error =\n","\n","    ## 모든 데이터에 따른 error 값\n","    print(\"epoch: \", i, \"error : \", total_error/len(x_data))"],"metadata":{"id":"dpiZkgjfHfkY"},"execution_count":null,"outputs":[]}]}