{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "#from google.colab import userdata\n",
    "\n",
    "# openai.api_key = 'sk-proj-JmXIBJ4HZfgQ47BuKP0uT3BlbkFJnY7JKAkk3p6Z6LHHUmtL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동으로 댓글을 달기 위해 맥락을 설정하는 프롬프트\n",
    "# 긍정, 부정 댓글을 분류하고 이에 맞는 댓글을 생성\n",
    "system_prompt = \"\"\"\n",
    "Act as a kind and excellent restaurant owner.\n",
    "Respond to the user-written comment.\n",
    "For negative comments, provide a detailed apology and mention specific areas for improvement.\n",
    "For positive comments, express your gratitude in detail.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lim(input_text):\n",
    "    #openai의 모델과 통신을 하는 코드\n",
    "    completion = openai.chat.completion.create(\n",
    "        #답변할 lim 모델 종류\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        # role : systemp 상황과 lim이 취할 입장에 대한 내용\n",
    "        # role :user -> 우리가 입력하고자하는 내용 (lim에 질의하고자 하는 내용)\n",
    "        messages = [{\"role\" : 'system', 'content' : system_prompt},\n",
    "                    {'role':'user', 'content':input_text}])\n",
    "    #답변을 변수에 담아 리턴\n",
    "    response_message = completion.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/var/folders/1b/bsw8d2sn1v76jr_rtvxbmtfm0000gn/T/tmp_ver6ymu',\n",
       " <http.client.HTTPMessage at 0x16020d370>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/dataset/tarrr_sample_submit.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_reply(input_text):\n",
    "    output = lim(input_text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>완전 내 스타일이에요! 가격도 적당하고 위치도 좋고👌</td>\n",
       "      <td>의견 감사합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>맛있긴 한데 양이 너무 적어서 좀... ㅠ</td>\n",
       "      <td>의견 감사합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>완전 내 스타일이에요 ㅠㅠ 여기 매장 분위기도 이쁨</td>\n",
       "      <td>의견 감사합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>한국의 전통 음식을 잘 표현한 것 같아요. 향토음식의 정취가 느껴져 좋았습니다.</td>\n",
       "      <td>의견 감사합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>서빙하는 분이 좀 불친절해서 기분이 좀 그랬어요.</td>\n",
       "      <td>의견 감사합니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment      reply\n",
       "0   1                 완전 내 스타일이에요! 가격도 적당하고 위치도 좋고👌  의견 감사합니다.\n",
       "1   2                       맛있긴 한데 양이 너무 적어서 좀... ㅠ  의견 감사합니다.\n",
       "2   3                  완전 내 스타일이에요 ㅠㅠ 여기 매장 분위기도 이쁨  의견 감사합니다.\n",
       "3   4  한국의 전통 음식을 잘 표현한 것 같아요. 향토음식의 정취가 느껴져 좋았습니다.  의견 감사합니다.\n",
       "4   5                   서빙하는 분이 좀 불친절해서 기분이 좀 그랬어요.  의견 감사합니다."
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 파일 경로 설정\n",
    "file_path = './comment_reply.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "\n",
    "# 데이터프레임 출력\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m     comment \u001b[38;5;241m=\u001b[39m v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]/[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment:\u001b[39m\u001b[38;5;124m'\u001b[39m, comment)\n",
      "Cell \u001b[0;32mIn[106], line 4\u001b[0m, in \u001b[0;36mgenerate_reply\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_reply\u001b[39m(input_text):\n\u001b[0;32m----> 4\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mlim\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[104], line 3\u001b[0m, in \u001b[0;36mlim\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlim\u001b[39m(input_text):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#openai의 모델과 통신을 하는 코드\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mcompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m#답변할 lim 모델 종류\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# role : systemp 상황과 lim이 취할 입장에 대한 내용\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# role :user -> 우리가 입력하고자하는 내용 (lim에 질의하고자 하는 내용)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m : system_prompt},\n\u001b[1;32m      9\u001b[0m                     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m:input_text}])\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#답변을 변수에 담아 리턴\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     response_message \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "total = len(df)\n",
    "\n",
    "# 데이터프레임 순회\n",
    "for i, v in df.iterrows():\n",
    "    comment = v['comment']\n",
    "    reply = generate_reply(comment)\n",
    "\n",
    "    print(f'[{i+1}]/[{total}]')\n",
    "    print('comment:', comment)\n",
    "    print('reply:', reply)\n",
    "    print('==========')\n",
    "    \n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "상냥하고 다정한 태도로 질문에 답변해줘.\n",
    "유저의 질문에 대해서 대화 매너와 예의를 잘 지키면서,\n",
    "네가 알고 있느 ㄴ최대한 잘 답변해주면 좋겠다.\n",
    "한국어로 답변해야 해\n",
    "'''\n",
    "def llm(input_text):\n",
    "  completion = openai.chat.completions.create(\n",
    "      model = \"gpt-3.5-turbo\",\n",
    "      messages = [\n",
    "          {\"role\":\"system\", \"content\":system_prompt},\n",
    "          {\"role\":\"user\", \"content\":input_text}\n",
    "      ]\n",
    "  )\n",
    "  output = completion.choices[0].message.content\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#내가 입력한 메시지가 li에게 전달되어 답변을 인쇄\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m ai_message \u001b[38;5;241m=\u001b[39m \u001b[43mchat_with_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAi>>>>\u001b[39m\u001b[38;5;124m\"\u001b[39m, ai_message)\n",
      "Cell \u001b[0;32mIn[112], line 5\u001b[0m, in \u001b[0;36mchat_with_user\u001b[0;34m(user_message)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat_with_user\u001b[39m(user_message):\n\u001b[0;32m----> 5\u001b[0m     ai_message \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ai_message\n",
      "Cell \u001b[0;32mIn[109], line 8\u001b[0m, in \u001b[0;36mllm\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm\u001b[39m(input_text):\n\u001b[0;32m----> 8\u001b[0m   completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      9\u001b[0m       model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m       messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:system_prompt},\n\u001b[1;32m     12\u001b[0m           {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:input_text}\n\u001b[1;32m     13\u001b[0m       ]\n\u001b[1;32m     14\u001b[0m   )\n\u001b[1;32m     15\u001b[0m   output \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'chat'"
     ]
    }
   ],
   "source": [
    "#위에서 정의한 lim 함수를 이용하여,\n",
    "# user_message를 전달하여, ai_message라는 답변을 받는 함수\n",
    "\n",
    "def chat_with_user(user_message):\n",
    "    ai_message = llm(user_message)\n",
    "    return ai_message\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"user >>>\")\n",
    "    if user_message.lower() ==\"quit\":\n",
    "        break\n",
    "\n",
    "    #내가 입력한 메시지가 li에게 전달되어 답변을 인쇄\n",
    "    ai_message = chat_with_user(user_message)\n",
    "    print(\"Ai>>>>\", ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(input_text, chat_history):\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlueMoonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
